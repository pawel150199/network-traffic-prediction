{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def import_data(directory: str) -> None:\n",
    "    data = []\n",
    "    results = []\n",
    "\n",
    "    for i in os.listdir(directory):\n",
    "        d = np.genfromtxt(f\"{directory}/{i}/requests.csv\", delimiter=',', skip_header=1, dtype=float)\n",
    "        data.append(d[:, 1:])\n",
    "        results.append(np.genfromtxt(f\"{directory}/{i}/results.txt\", dtype=float, usecols=(1,)))\n",
    "\n",
    "    return np.array(data), np.array(results)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.contrib import learn as tflearn\n",
    "from tensorflow.contrib import layers as tflayers\n",
    "\n",
    "\n",
    "def lstm_model(num_units, rnn_layers, dense_layers=None, learning_rate=0.1, optimizer='Adagrad'):\n",
    "    \"\"\"\n",
    "    Creates a deep model based on:\n",
    "        * stacked lstm cells\n",
    "        * an optional dense layers\n",
    "    :param num_units: the size of the cells.\n",
    "    :param rnn_layers: list of int or dict\n",
    "                         * list of int: the steps used to instantiate the `BasicLSTMCell` cell\n",
    "                         * list of dict: [{steps: int, keep_prob: int}, ...]\n",
    "    :param dense_layers: list of nodes for each layer\n",
    "    :return: the model definition\n",
    "    \"\"\"\n",
    "\n",
    "    def lstm_cells(layers):\n",
    "        if isinstance(layers[0], dict):\n",
    "            return [tf.contrib.rnn.DropoutWrapper(\n",
    "                tf.contrib.rnn.BasicLSTMCell(\n",
    "                    layer['num_units'], state_is_tuple=True\n",
    "                ),\n",
    "                layer['keep_prob']\n",
    "            ) if layer.get('keep_prob') else tf.contrib.rnn.BasicLSTMCell(\n",
    "                    layer['num_units'],\n",
    "                    state_is_tuple=True\n",
    "                ) for layer in layers\n",
    "            ]\n",
    "        return [tf.contrib.rnn.BasicLSTMCell(steps, state_is_tuple=True) for steps in layers]\n",
    "\n",
    "    def dnn_layers(input_layers, layers):\n",
    "        if layers and isinstance(layers, dict):\n",
    "            return tflayers.stack(input_layers, tflayers.fully_connected,\n",
    "                                  layers['layers'],\n",
    "                                  activation=layers.get('activation'),\n",
    "                                  dropout=layers.get('dropout'))\n",
    "        elif layers:\n",
    "            return tflayers.stack(input_layers, tflayers.fully_connected, layers)\n",
    "        else:\n",
    "            return input_layers\n",
    "\n",
    "    def _lstm_model(X, y):\n",
    "        stacked_lstm = tf.contrib.rnn.MultiRNNCell(lstm_cells(rnn_layers), state_is_tuple=True)\n",
    "        x_ = tf.unstack(X, axis=1, num=num_units)\n",
    "        output, layers = tf.contrib.rnn.static_rnn(stacked_lstm, x_, dtype=dtypes.float32)\n",
    "        output = dnn_layers(output[-1], dense_layers)\n",
    "        prediction, loss = tflearn.models.linear_regression(output, y)\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss, tf.contrib.framework.get_global_step(), optimizer=optimizer,\n",
    "            learning_rate=learning_rate)\n",
    "        return prediction, loss, train_op\n",
    "\n",
    "    return _lstm_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, results = import_data(\"Euro28\")\n",
    "\n",
    "data = data.reshape(100,300)\n",
    "results = results[:, 1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, results, test_size=0.2, random_state=1410)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lstm = lstm_model(r)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.9 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}